{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM3d13C1UDDt6mmTKvyCtLJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Text processing"],"metadata":{"id":"W7liv6haBNZb"}},{"cell_type":"markdown","source":["## Environment setup"],"metadata":{"id":"fm2NRDIAqEzI"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8031,"status":"ok","timestamp":1750782184897,"user":{"displayName":"Miguel Angel Pardo","userId":"16900940354237523056"},"user_tz":-120},"id":"IQl1rr6FSpKO","outputId":"c7f19de2-21be-4e50-ea66-d2fa4ce49625"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","source":["WORKING_PATH = '/content/drive/MyDrive/KeepCoding/NLP/exercise'\n"],"metadata":{"id":"ysmWbEeS5h5o"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1132,"status":"ok","timestamp":1750782186033,"user":{"displayName":"Miguel Angel Pardo","userId":"16900940354237523056"},"user_tz":-120},"id":"TF0i-O5oTIwc","outputId":"24f4ef64-5d4e-49e3-c256-29c41f340fe4"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/KeepCoding/NLP/exercise\n"]}],"source":["%cd {WORKING_PATH}"]},{"cell_type":"code","source":["!pip install -r requirements.txt"],"metadata":{"id":"T4InpvkuquUm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys\n","import pandas as pd\n","import numpy as np\n","import os\n","import re\n","from wordcloud import WordCloud, STOPWORDS\n","import unicodedata\n","from num2words import num2words\n","from nltk.stem.porter import PorterStemmer\n","from sklearn.model_selection import train_test_split\n","import pickle"],"metadata":{"id":"NSKbPus5P6b0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# to load custom libraries\n","sys.path.append(WORKING_PATH)\n","\n","# load custom libraries"],"metadata":{"id":"hqibiYKAE_ta"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pyct7ps9okI1","executionInfo":{"status":"ok","timestamp":1750783198546,"user_tz":-120,"elapsed":390,"user":{"displayName":"Miguel Angel Pardo","userId":"16900940354237523056"}},"outputId":"0cf64f00-795b-490b-86f7-c1d93ed6151f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(13272, 9)"]},"metadata":{},"execution_count":16}],"source":["# Read data\n","data = pd.read_json('reviews_Patio_Lawn_and_Garden_5.json', lines=True)\n","data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8j_SwxwopG1s"},"outputs":[],"source":["# Split into train and test datasets\n","reviewText_train, reviewText_test, overall_train, overall_test = train_test_split(\n","    data['reviewText'], data['overall'],\n","    train_size=0.75, test_size=0.25,\n","    random_state=42, shuffle=True\n",")"]},{"cell_type":"code","source":["def normalize_ASCII(text):\n","  \"\"\"\n","  Normalizes Unicode text to its ASCII representation by decomposing complex characters,\n","  removing non-ASCII characters, and returning a clean UTF-8 string.\n","  \"\"\"\n","  text = unicodedata.normalize('NFKD', text) # Break down Unicode Characters\n","  text = text.encode('ascii', 'ignore') # Convert to ASCII\n","  text = text.decode('utf-8', 'ignore') # Decode back to UTF-8\n","  return text\n","\n","def cleanning(text):\n","  \"\"\"\n","  Cleans text by:\n","  1. Removing all punctuation except apostrophes (for contractions)\n","  2. Eliminating single-letter words\n","  \"\"\"\n","  text = re.sub(r\"[^a-z0-9']\", ' ', text) # Remove punctuation. Only words, spaces and ' are kept. Keep ' is important for removing stopwords step.\n","  text = re.sub(r\" [a-z] \", ' ', text) # Remove one letter words\n","  return text\n","\n","def remove_stopwords(text, stopwords):\n","  \"\"\"\n","  Removes stopwords and apostrophes from input text, preserving meaningful words.\n","  \"\"\"\n","  list_words = []\n","  for word in text.split():\n","    if word not in stopwords: # Remove stopwords\n","      list_words.append(word)\n","  cleaned_text = ' '.join(list_words)\n","  cleaned_text = re.sub(r\"'\", '', cleaned_text) # Remove punctuation '\n","  return cleaned_text\n","\n","def numbers2words(text):\n","  \"\"\"\n","  Converts all numeric digits in a text string to their word equivalents\n","  \"\"\"\n","  list_words = []\n","  for word in text.split():\n","    if word.isdigit():\n","      list_words.append(num2words(word, ordinal=False))\n","    else:\n","      list_words.append(word)\n","  new_text = ' '.join(list_words)\n","  return new_text\n","\n","def stemming(text):\n","  \"\"\"\n","  Applies Porter stemming to each word in the input text, reducing words to their root forms.\n","  \"\"\"\n","  stemmer = PorterStemmer()\n","  list_words = []\n","  for word in text.split():\n","    list_words.append(PorterStemmer().stem(word))\n","  return ' '.join(list_words)\n","\n","def overall2label(overall):\n","  \"\"\"\n","  Converts a numerical 'overall' rating into a binary label:\n","  - 0 for ratings below 4 (negative)\n","  - 1 for ratings 4 or above (positive)\n","  \"\"\"\n","  label = None\n","  if overall < 4:\n","    label = 0\n","  else:\n","    label = 1\n","  return label"],"metadata":{"id":"qAikA_eBB-u_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def review2words(text):\n","  \"\"\"\n","  Applies a complete text preprocessing pipeline to normalize and clean input text.\n","  Performs the following transformations in sequence:\n","  1. Converts to lowercase\n","  2. Normalizes Unicode to ASCII\n","  3. Cleans punctuation and single-letter words\n","  4. Removes stopwords\n","  5. Applies stemming\n","  6. Converts numbers to words\n","  \"\"\"\n","  text = text.lower() # To lowercase\n","  text = normalize_ASCII(text)\n","  text = cleanning(text)\n","  text = remove_stopwords(text, STOPWORDS)\n","  text = stemming(text)\n","  text = numbers2words(text)\n","  words = text.split()\n","  return words"],"metadata":{"id":"JHTY1uLBSRNS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check processing\n","print(f'Before:\\n{data.loc[201,\"reviewText\"]}')\n","print(f'After:\\n{review2words(data.loc[201,\"reviewText\"])}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AIU_FBd3DELD","executionInfo":{"status":"ok","timestamp":1750783229219,"user_tz":-120,"elapsed":12,"user":{"displayName":"Miguel Angel Pardo","userId":"16900940354237523056"}},"outputId":"f4f593b6-ea1f-407c-9d2f-ed2b9ef543f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Before:\n","This chain fit great for my Poulan Pro electric saw. This is also an older company that has a great website to help identify exactly what model your specific saw requires. It is not directional, so you don't have to worry about any arrows facing the right way. I just used it and I forgot how powerful my saw was. Getting old ones sharpened can be questionable when new ones are this cheap.\n","After:\n","['chain', 'fit', 'great', 'poulan', 'pro', 'electr', 'saw', 'older', 'compani', 'great', 'websit', 'help', 'identifi', 'exactli', 'model', 'specif', 'saw', 'requir', 'direct', 'worri', 'arrow', 'face', 'right', 'way', 'use', 'forgot', 'power', 'saw', 'get', 'old', 'one', 'sharpen', 'question', 'new', 'one', 'cheap']\n"]}]},{"cell_type":"code","source":["cache_dir = \"cache\"\n","os.makedirs(cache_dir, exist_ok=True)\n","\n","def preprocess_data(data_train, data_test, labels_train, labels_test,\n","                    cache_dir=cache_dir, cache_file=\"preprocessed_data.pkl\"):\n","    \"\"\"\n","    Preprocesses training and test data by:\n","    1. Converting reviews to tokenized words\n","    2. Transforming ratings to binary labels\n","    3. Caching/loading processed data for efficiency\n","    \"\"\"\n","\n","    cache_data = None\n","    if cache_file is not None:\n","        try:\n","            with open(os.path.join(cache_dir, cache_file), \"rb\") as f:\n","                cache_data = pickle.load(f)\n","            print(\"Read preprocessed data from cache file:\", cache_file)\n","        except:\n","            pass\n","\n","    if cache_data is None:\n","        words_train = list(map(review2words, data_train))\n","        words_test = list(map(review2words, data_test))\n","        labels_train = list(map(overall2label, labels_train))\n","        labels_test = list(map(overall2label, labels_test))\n","\n","        if cache_file is not None:\n","            cache_data = dict(words_train=words_train, words_test=words_test,\n","                              labels_train=labels_train, labels_test=labels_test)\n","            with open(os.path.join(cache_dir, cache_file), \"wb\") as f:\n","                pickle.dump(cache_data, f)\n","            print(\"Wrote preprocessed data to cache file:\", cache_file)\n","    else:\n","        words_train, words_test, labels_train, labels_test = (cache_data['words_train'],\n","                cache_data['words_test'], cache_data['labels_train'], cache_data['labels_test'])\n","\n","    return words_train, words_test, labels_train, labels_test"],"metadata":{"id":"jzSvD7b4OoIp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["words_train, words_test, labels_train, labels_test = preprocess_data(reviewText_train, reviewText_test, overall_train, overall_test, cache_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MVJ6xYMBmDEs","executionInfo":{"status":"ok","timestamp":1750783277192,"user_tz":-120,"elapsed":41882,"user":{"displayName":"Miguel Angel Pardo","userId":"16900940354237523056"}},"outputId":"05a34a01-17dc-4976-80d7-14cd1ecc9ad4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Wrote preprocessed data to cache file: preprocessed_data.pkl\n"]}]}]}